---
title: "Convolutional Operations Workshop"
collection: talks
type: "Workshop"
permalink: /talks/2019-06-08-workshop-5
venue: "Deepcon"
date: 2019-06-08
location: "Tokyo, Japan"
---

The MLT workshop on CNN Architectures has conducted by our MLT Core Team Engineers Dimitris Katsios, Mustafa Yagmur and Alisher Abdulkhaev.

__Part 1: A Historical Review of Deep CNNs__

__Part 2: Popular CNN Architectures (interactive implementation)__

- VGG-Net: 3x3 vs 11x11 Convolution

- Inception-Net: “1x1 convolution” vs “Fully Connected”

- Xception: Separable Convolutions in Inception-Networks

- MobileNet: Depthwise (Separable) Convolutions for Training Light Models

- ResNet: Residuals in Convolution Operations

- DenseNet: Dense Connections in Convolution Operations

- SqueezeNet: Distributed Training of Networks

__Part 3: Advanced Deep CNN Architectures (short summary only)__

- ShuffleNet

- Squeeze and Excitation Networks (SENet)

- Feature Pyramid Networks (FPNs)

- Neural ODEs


![Learning in Deep Networks](https://alisher-ai.github.io/files/2019-06-08-workshop-5.png)

[More information here](https://www.meetup.com/Machine-Learning-Tokyo/events/261792822/)

